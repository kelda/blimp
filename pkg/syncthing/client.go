package syncthing

import (
	"bytes"
	"context"
	"fmt"
	"io/ioutil"
	"os"
	"os/exec"
	"path/filepath"
	"sort"
	"strings"
	"time"

	rice "github.com/GeertJohan/go.rice"
	log "github.com/sirupsen/logrus"

	"github.com/kelda-inc/blimp/pkg/cfgdir"
	"github.com/kelda-inc/blimp/pkg/errors"
	"github.com/kelda-inc/blimp/pkg/hash"
	"github.com/kelda-inc/blimp/pkg/proto/node"
	"github.com/kelda-inc/blimp/pkg/strs"
)

var stbinPath = cfgdir.Expand("stbin")

const stignoreHeader = `# Generated by Blimp. DO NOT EDIT.
# This file is used by Blimp to control what files are synced.`

type Client struct {
	mounts  []Mount
	volumes []string
}

func (c Client) GetIDPathMap() map[string]string {
	idPathMap := map[string]string{}
	for _, m := range c.mounts {
		idPathMap[m.ID()] = m.Path
	}
	return idPathMap
}

type Mount struct {
	Path    string
	Include []string
	SyncAll bool
}

// GetStignore returns the stignore file needed to include only the paths in
// `Mount.Include`.
// In order to sync subdirectories, we have to add explicit rules allowing each
// parent directory, and ignoring all other files in the parent directory. For example,
// to sync the directory /foo/bar/, we have to use a stignore of the form:
// ```
// !/foo/bar # Include the target directory.
// /foo/	 # Exclude all other files in /foo, but not /foo itself.
// !/foo     # Include /foo.
// ```
// If we didn't have the latter two rules, /foo/bar wouldn't get synced, since
// the directory /foo would never get created.
// See this issue for more information: https://github.com/syncthing/syncthing/issues/2091.
func (m Mount) GetStignore() (stignore string, needed bool) {
	if m.SyncAll {
		return "", false
	}

	var allRules []string
	for _, include := range m.Include {
		allRules = append(allRules, rulesToIncludePath(include)...)
	}
	allRules = strs.Unique(allRules)

	// Sort the rules so that more specific rules are matched first.
	// This is necessary to properly merge rules when there are multiple
	// Includes, since any rules to explicitly include files/directories must
	// come before the exclusion rule for its parent.
	sort.Slice(allRules, func(i, j int) bool {
		left := allRules[i]
		right := allRules[j]

		// If the rule is for a path deeper in the filesystem tree, it's more
		// specific.
		depth := func(rule string) int {
			return strings.Count(filepath.Clean(rule), "/")
		}
		if depth(left) > depth(right) {
			return true
		}
		if depth(right) > depth(left) {
			return false
		}

		// A directory with a trailing / is more specific, since it only
		// matches the directory's contents, and doesn't match the directory's
		// name.
		onlyDirContents := func(rule string) bool {
			return strings.HasSuffix(rule, "/")
		}
		if onlyDirContents(left) && !onlyDirContents(right) {
			return true
		}
		if !onlyDirContents(left) && onlyDirContents(right) {
			return false
		}

		// The rules are siblings, and their order doesn't matter.
		return left < right
	})

	return fmt.Sprintf(`%s

%s

# Ignore all other files.
**
`, stignoreHeader, strings.Join(allRules, "\n")), true
}

func (m Mount) ID() string {
	return hash.DnsCompliant(m.Path)
}

// Syncs returns whether the mount already syncs the given child.
func (m Mount) Syncs(child string) bool {
	if m.SyncAll {
		return true
	}

	for _, include := range m.Include {
		_, ok := getSubpath(include, child)
		if ok {
			return true
		}
	}
	return false
}

func NewClient(volumes []string) Client {
	var allMounts []Mount
	// Collect all the mounts, regardless of whether they're nested.
	for _, volume := range volumes {
		// For directories, we just mount the entire directory. For other
		// files, we mount the parent directory, and use .stignore to only sync
		// the desired files.
		if isDir(volume) {
			allMounts = append(allMounts, Mount{
				Path:    volume,
				SyncAll: true,
			})
		} else {
			allMounts = append(allMounts, Mount{
				Path:    filepath.Dir(volume),
				Include: []string{filepath.Base(volume)},
			})
		}
	}

	// Collapse nested mounts to avoid confusing Syncthing.
	// We first sort the mounts from shallowest to deepest. This way, we know
	// that the first mount that matches a path is the most efficient match.
	sort.Slice(allMounts, func(i, j int) bool {
		depth := func(path string) int {
			return strings.Count(path, string(filepath.Separator))
		}
		return depth(allMounts[i].Path) < depth(allMounts[j].Path)
	})

	// Starting from the highest-level directories, try to greedily combine
	// child mounts.
	var collapsedMounts []Mount
	// skipIndices tracks mounts that have been collapsed already.
	skipIndices := map[int]struct{}{}
	for pi, parent := range allMounts {
		if _, ok := skipIndices[pi]; ok {
			continue
		}

		for mi := pi + 1; mi < len(allMounts); mi++ {
			if _, ok := skipIndices[mi]; ok {
				continue
			}

			mount := allMounts[mi]
			relPath, ok := getSubpath(parent.Path, mount.Path)
			if !ok {
				// The mount isn't nested within the parent.
				continue
			}

			switch {
			// If the parent already syncs this mount, then any includes for
			// files don't matter since they'll be automatically picked up.
			case parent.Syncs(relPath):
				// Don't need to do anything.

			// If we're syncing an entire subdirectory, add the relative
			// path to the subdirectory to the include list.
			case mount.SyncAll:
				// If it's the same path, then just modify the parent to sync
				// all the files.
				if relPath == "." {
					parent.SyncAll = true
					parent.Include = nil
				} else {
					// Otherwise, add the relative path to the subdirectory to the
					// include list.
					parent.Include = append(parent.Include, relPath)
				}

			// If we're syncing an individual file, add the individual file to
			// the include list.
			default:
				for _, include := range mount.Include {
					parent.Include = append(parent.Include, filepath.Join(relPath, include))
				}
			}
			skipIndices[mi] = struct{}{}
		}

		collapsedMounts = append(collapsedMounts, parent)
	}

	return Client{
		mounts:  collapsedMounts,
		volumes: volumes,
	}
}

func (c Client) Run(ctx context.Context, ncc node.ControllerClient, remoteAPIAddr,
	token string) ([]byte, error) {

	idPathMap := c.GetIDPathMap()
	if err := c.WriteConfig(idPathMap); err != nil {
		return nil, errors.WithContext("write config", err)
	}

	finishedInitialSync := make(chan struct{}, 1)
	go runSyncCompletionServer(ctx, ncc, token, finishedInitialSync)

	var out bytes.Buffer
	cmd := exec.CommandContext(ctx, stbinPath, "-verbose", "-home", cfgdir.Expand(""),
		"-logfile", cfgdir.Expand("syncthing.log"))
	cmd.Stderr = &out
	cmd.Stdout = &out
	if err := cmd.Start(); err != nil {
		return nil, errors.WithContext("start syncthing", err)
	}

	initialSyncCtx, cancelInitialSync := context.WithCancel(ctx)
	waitErrChan := make(chan error)
	go func() {
		waitErrChan <- cmd.Wait()
		cancelInitialSync()
	}()

	initialSyncErr := make(chan error)
	go func() {
		initialSyncErr <- c.performInitialSync(initialSyncCtx, remoteAPIAddr, idPathMap)
	}()

	select {
	// If Syncthing crashes, abort the sync, and return immediately.
	case err := <-waitErrChan:
		cancelInitialSync()
		return out.Bytes(), errors.WithContext("syncthing crashed", err)
	case err := <-initialSyncErr:
		if err != nil {
			return nil, errors.WithContext("initial sync failed", err)
		}
	}

	finishedInitialSync <- struct{}{}

	waitErr := <-waitErrChan
	return out.Bytes(), waitErr
}

func (c Client) performInitialSync(ctx context.Context, remoteAPIAddr string, idPathMap map[string]string) error {
	localAPI := APIClient{fmt.Sprintf("localhost:%d", APIPort)}
	remoteAPI := APIClient{remoteAPIAddr}

	var folders []string
	for folder := range idPathMap {
		folders = append(folders, folder)
	}

	// Wait for the Syncthing daemons to boot. The connections may fail at
	// first since the tunnels are started asynchronously.
	waitCtx, _ := context.WithTimeout(ctx, 5*time.Minute)
	if err := waitUntilConnected(waitCtx, localAPI, remoteAPI); err != nil {
		return errors.WithContext("wait for devices to connect", err)
	}

	if err := waitUntilScanned(ctx, localAPI, folders); err != nil {
		return errors.WithContext("wait for initial scan", err)
	}

	if err := waitUntilSynced(ctx, localAPI, remoteAPI, folders); err != nil {
		return errors.WithContext("wait for initial sync", err)
	}

	if err := setLocalFolderType(ctx, localAPI, "sendreceive", idPathMap); err != nil {
		return errors.WithContext("switch to sendreceive", err)
	}

	return nil
}

func (c Client) WriteConfig(idPathMap map[string]string) error {
	err := MakeMarkers(idPathMap)
	if err != nil {
		return errors.WithContext("make markers", err)
	}

	for _, m := range c.mounts {
		// Remove any stale stignores. This avoids an issue where a previous
		// run mounts a file in a directory, which creates an stignore, and the
		// user modifies their volumes to mount the entire directory.
		// In that case, we should run with no stignore at all.
		if contents, err := ioutil.ReadFile(".stignore"); err == nil {
			if strings.Contains(string(contents), stignoreHeader) {
				if err := os.Remove(".stignore"); err != nil {
					return errors.WithContext("remove stignore", err)
				}
			}
		}

		stignore, ok := m.GetStignore()
		if !ok {
			continue
		}

		path := filepath.Join(m.Path, ".stignore")
		err := ioutil.WriteFile(path, []byte(stignore), 0644)
		if err != nil {
			return errors.WithContext("write stignore", err)
		}

		go ensureFileExists(path, stignore)
	}

	box := rice.MustFindBox("stbin")
	stbinBytes, err := box.Bytes("")
	if err != nil {
		// This really really can't happen as stbin is supposed to be
		// literally embedded in this binary.  A panic is actually
		// appropriate.
		panic(err)
	}

	err = ioutil.WriteFile(stbinPath, stbinBytes, 0755)
	if err != nil {
		return errors.WithContext("write stbin error", err)
	}

	fileMap := map[string]string{
		"config.xml": makeConfig(false, idPathMap, "sendonly"),
		"cert.pem":   cert,
		"key.pem":    key,
	}
	for path, data := range fileMap {
		err := ioutil.WriteFile(cfgdir.Expand(path), []byte(data), 0644)
		if err != nil {
			return errors.WithContext("write config", err)
		}
	}

	return nil
}

func ensureFileExists(path, contents string) {
	for {
		err := ioutil.WriteFile(path, []byte(contents), 0644)
		if err != nil {
			log.WithField("path", path).WithError(err).Warn("Failed to write file")
		}
		time.Sleep(30 * time.Second)
	}
}

var isDir = func(path string) bool {
	fi, err := os.Stat(path)

	// Create the path as a directory if it doesn't exist.
	if os.IsNotExist(err) {
		if err := os.MkdirAll(path, 0755); err != nil {
			log.
				WithError(err).
				WithField("path", path).
				Fatal("Tried to create directory for non-existent bind volume, but failed")
		}
		return true
	}

	return err == nil && fi.IsDir()
}

func getSubpath(parent, child string) (string, bool) {
	relPath, err := filepath.Rel(parent, child)
	if err != nil || strings.HasPrefix(relPath, "..") {
		return "", false
	}
	return relPath, true
}

func rulesToIncludePath(path string) (rules []string) {
	for {
		rules = append(rules,
			// Include the path.
			fmt.Sprintf("!/%s", path),
		)

		parent := filepath.Dir(path)
		if parent == "." {
			return rules
		}

		// Exclude all other files in the parent directory (except for the
		// parent directory itself).
		rules = append(rules, fmt.Sprintf("/%s/", parent))
		path = parent
	}
}
